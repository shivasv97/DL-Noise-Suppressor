{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "noise_suppressor_8khz_1800_samples_final_copy.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Qk66Mg9Y-5tP",
        "CJ23sidwhoj4",
        "1verZ-A4hoj5",
        "oOpuJe4VhokR",
        "ZOjUa34ohokY",
        "iju_w631hokc",
        "r90kcqqxhoki",
        "LFeY4QoAOVws",
        "QDYUGGfFholP",
        "DZk6g4kMhols",
        "FzM_hYPzholw",
        "iOzug_gMhol0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk66Mg9Y-5tP"
      },
      "source": [
        "# A. Setting up Google Colab and Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76SSzn7DK5tb"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtB-TQQCLAMB",
        "outputId": "258e79dc-2f74-490f-cac1-793bb4f8bb71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MS-SNSD  noise_suppressor.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ23sidwhoj4"
      },
      "source": [
        "# B. Setting up the required Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAct2bSphoj4"
      },
      "source": [
        "### Cloning Dataset Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrQk4bKOwT8K"
      },
      "source": [
        "!git clone https://github.com/microsoft/MS-SNSD.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1verZ-A4hoj5"
      },
      "source": [
        "### Installing required modules for creating required data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "171zazcn5UrW",
        "outputId": "57526dc4-ac7a-4830-b878-6604be2209d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!pip install -r ./MS-SNSD/requirements.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: './MS-SNSD/requirements.txt'\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjC80pv3WAtB",
        "outputId": "bc7bfbfe-09ff-4b02-ed7a-849644a79788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install pysoundfile"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pysoundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/b3/0b871e5fd31b9a8e54b4ee359384e705a1ca1e2870706d2f081dc7cc1693/PySoundFile-0.9.0.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.6/dist-packages (from pysoundfile) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=0.6->pysoundfile) (2.20)\n",
            "Installing collected packages: pysoundfile\n",
            "Successfully installed pysoundfile-0.9.0.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCGf9goehokC"
      },
      "source": [
        "#### As of the date when this code was developed, Dataset processing works only with the below NumPy version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsDVxVwb-Fiz",
        "outputId": "3b533fe9-2fc6-4b2f-f8e0-6ab3f8f29ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python -m pip install numpy==1.16.4"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 1023, in _handle_fromlist\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 83, in <module>\n",
            "    __import__('pip._vendor.packaging.specifiers')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/packaging/specifiers.py\", line 266, in <module>\n",
            "    class Specifier(_IndividualSpecifier):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/packaging/specifiers.py\", line 361, in Specifier\n",
            "    _regex = re.compile(r\"^\\s*\" + _regex_str + r\"\\s*$\", re.VERBOSE | re.IGNORECASE)\n",
            "  File \"/usr/lib/python3.6/re.py\", line 233, in compile\n",
            "    return _compile(pattern, flags)\n",
            "  File \"/usr/lib/python3.6/re.py\", line 301, in _compile\n",
            "    p = sre_compile.compile(pattern, flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 566, in compile\n",
            "    code = _code(p, flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 551, in _code\n",
            "    _compile(code, p.data, flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 146, in _compile\n",
            "    _compile(code, p, (flags | add_flags) & ~del_flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 187, in _compile\n",
            "    _compile(code, av, flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 146, in _compile\n",
            "    _compile(code, p, (flags | add_flags) & ~del_flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 134, in _compile\n",
            "    _compile(code, av[2], flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 146, in _compile\n",
            "    _compile(code, p, (flags | add_flags) & ~del_flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 146, in _compile\n",
            "    _compile(code, p, (flags | add_flags) & ~del_flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 187, in _compile\n",
            "    _compile(code, av, flags)\n",
            "  File \"/usr/lib/python3.6/sre_compile.py\", line 81, in _compile\n",
            "    if flags & SRE_FLAG_IGNORECASE:\n",
            "  File \"/usr/lib/python3.6/enum.py\", line 806, in __and__\n",
            "    return self.__class__(self._value_ & self.__class__(other)._value_)\n",
            "  File \"/usr/lib/python3.6/enum.py\", line 293, in __call__\n",
            "    return cls.__new__(cls, value)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/__main__.py\", line 16, in <module>\n",
            "    from pip._internal.main import main as _main  # isort:skip # noqa\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/main.py\", line 13, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/autocompletion.py\", line 11, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/main_parser.py\", line 7, in <module>\n",
            "    from pip._internal.cli import cmdoptions\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/cmdoptions.py\", line 28, in <module>\n",
            "    from pip._internal.models.target_python import TargetPython\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/models/target_python.py\", line 4, in <module>\n",
            "    from pip._internal.utils.misc import normalize_version_info\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/misc.py\", line 19, in <module>\n",
            "    from pip._vendor import pkg_resources\n",
            "  File \"<frozen importlib._bootstrap>\", line 1023, in _handle_fromlist\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfMUaUue_BzR"
      },
      "source": [
        "!rm -rf /content/MS-SNSD/CleanSpeech_training"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbtEF-CM_GcL"
      },
      "source": [
        "!rm -rf /content/MS-SNSD/NoisySpeech_training"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJmD6K7MVmWu",
        "outputId": "3ede266e-37ae-488d-b2d6-fb12c9c24e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDh8GObWYHcW",
        "outputId": "a9cb5c1c-e695-4fe6-e34f-b4cdf7e62569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip list | grep librosa"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "librosa                       0.6.3          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpuJe4VhokR"
      },
      "source": [
        "### Run the python file in the dataset to generated the noisy_voice and clean_voice data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9vVyoM22-48",
        "outputId": "cc766255-89df-4dee-d6c8-c2841744a7bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!python ./MS-SNSD/noisyspeech_synthesizer.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file './MS-SNSD/noisyspeech_synthesizer.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UbBSRScAXuY",
        "outputId": "3992090c-5d44-4130-aa98-a6856726f90c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.15.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.8)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.5)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (50.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9SfcpAEObLj"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb55JORChokY"
      },
      "source": [
        "# C. Building the noise suppressor model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOjUa34ohokY"
      },
      "source": [
        "### 1. Library imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlWMIxVqBQ4M"
      },
      "source": [
        "import librosa\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy import stats\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import librosa.display\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, MaxPooling2D, Dropout, concatenate, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend\n",
        "import tensorflow as tf"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iju_w631hokc"
      },
      "source": [
        "### 2. Declaring Constant variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKgCaO8kBOP2",
        "outputId": "0df8c471-4973-4998-ec38-79071defc710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "DIM_SQ_SPEC = 128  # dimension required for the UNet to process the spectrogram input\n",
        "SAMPLE_RATE = 8000\n",
        "N_FFT = DIM_SQ_SPEC*2-1\n",
        "HOP_LENGTH = N_FFT//4 \n",
        "SQ_CLIP_LIMIT = math.floor(N_FFT/4)*math.ceil(N_FFT/2)\n",
        "\n",
        "print(\"N_FFT:\", N_FFT)\n",
        "print(\"HOP_LENGTH:\", HOP_LENGTH)\n",
        "print(\"SQ_CLIP_LIMIT:\", SQ_CLIP_LIMIT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N_FFT: 255\n",
            "HOP_LENGTH: 63\n",
            "SQ_CLIP_LIMIT: 8064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43mR8vMQ2UCL"
      },
      "source": [
        "### 3. Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r90kcqqxhoki"
      },
      "source": [
        "#### 3a. Split the audio signal into smaller frames to ensure a Square Spectrogram can be created from it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8CjfUT2_k1c"
      },
      "source": [
        "NOISE_DATASET_PATH = \"/content/drive/My Drive/Colab Notebooks/MS-SNSD/NoisySpeech_training\"\n",
        "CLEAN_DATASET_PATH = \"/content/drive/My Drive/Colab Notebooks/MS-SNSD/CleanSpeech_training\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-HQqKp9__zS"
      },
      "source": [
        "def fetch_filenames(path):\n",
        "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
        "        return filenames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et8-KwUbW2Bb"
      },
      "source": [
        "def signal_creator(noise_path, clean_path):\n",
        "    noise_signal, noise_sr = librosa.load(noise_path, sr=SAMPLE_RATE)\n",
        "    clean_signal, clean_sr = librosa.load(clean_path, sr=SAMPLE_RATE)\n",
        "    only_noise = noise_signal[:] - clean_signal[:]\n",
        "    return noise_signal, clean_signal, only_noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9JHFDoEs_82"
      },
      "source": [
        "def numpy_frame_creator(signal, signal_length=int(SAMPLE_RATE*1.1)):\n",
        "    frame_signal = librosa.util.frame(signal[:signal_length], frame_length=SQ_CLIP_LIMIT, hop_length=SQ_CLIP_LIMIT).T\n",
        "    return frame_signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFotPgvzuWbP",
        "outputId": "9c767ece-cab6-4981-b6d1-2fc1f703b355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "SAMPLE_RATE*1.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8800.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUMPoAZd2S1J"
      },
      "source": [
        "''' convert all .wav files to smaller frames to create spectograms with amplitude and phase component. '''\n",
        "# fetch and store the audio numpy array\n",
        "noise_filenames = fetch_filenames(NOISE_DATASET_PATH)\n",
        "clean_filenames = fetch_filenames(CLEAN_DATASET_PATH)\n",
        "\n",
        "print(\"Number of files: \", len(noise_filenames), len(clean_filenames))\n",
        "\n",
        "noise_frames = []\n",
        "clean_frames = []\n",
        "only_noise_frames = []\n",
        "for i, noise_file in enumerate(noise_filenames):\n",
        "    clean_file = noise_file.split(\"_\")[-1]\n",
        "    if (clean_file in clean_filenames):\n",
        "        noise_file = os.path.join(NOISE_DATASET_PATH, noise_file)\n",
        "        clean_file = os.path.join(CLEAN_DATASET_PATH, clean_file)\n",
        "        noise_signal, clean_signal, only_noise_signal = signal_creator(noise_file, clean_file)\n",
        "        noise_set = numpy_frame_creator(noise_signal)\n",
        "        clean_set = numpy_frame_creator(clean_signal)\n",
        "        only_noise_set = numpy_frame_creator(only_noise_signal)\n",
        "        noise_frames.append(noise_set)\n",
        "        clean_frames.append(clean_set)\n",
        "        only_noise_frames.append(only_noise_set)\n",
        "noise_frames = np.vstack(noise_frames)\n",
        "clean_frames = np.vstack(clean_frames)\n",
        "only_noise_frames = np.vstack(only_noise_frames)\n",
        "\n",
        "\n",
        "print(\"Shape of noise clean and only noise frames: \", noise_frames.shape, clean_frames.shape, only_noise_frames.shape)\n",
        "\n",
        "# divide them into frames and vstack and store them.\n",
        "# compute stft for them and store the mag and phase as seperate numpy arrays."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzzEAGsj7-ZN"
      },
      "source": [
        "np.save(\"/content/drive/My Drive/Colab Notebooks/signal_arr/noise_signal_8khz_1s\", noise_frames)\n",
        "np.save(\"/content/drive/My Drive/Colab Notebooks/signal_arr/clean_signal_8khz_1s\", clean_frames)\n",
        "np.save(\"/content/drive/My Drive/Colab Notebooks/signal_arr/only_noise_signal_8khz_1s\", only_noise_frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFeY4QoAOVws"
      },
      "source": [
        "#### 3b. Creating the spectogram for the frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK8UQUbXgFf4"
      },
      "source": [
        "def specto_mag_phase(signal_frame):\n",
        "    stft = librosa.core.stft(signal_frame, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
        "    stft_mag, stft_ph = librosa.core.magphase(stft)\n",
        "    stft_mag_db = librosa.core.amplitude_to_db(stft_mag)\n",
        "    return stft_mag_db, stft_ph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xzroty1gTrG"
      },
      "source": [
        "def signal_to_spect(signal):\n",
        "    n_frames = signal.shape[0]\n",
        "    signal_mag = np.zeros((n_frames, DIM_SQ_SPEC, DIM_SQ_SPEC))\n",
        "    signal_ph = np.zeros((n_frames, DIM_SQ_SPEC, DIM_SQ_SPEC), dtype=complex)\n",
        "\n",
        "    for i in range(n_frames):\n",
        "        signal_mag[i, :, :], signal_ph[i, :, :] = specto_mag_phase(signal[i])\n",
        "    return signal_mag, signal_ph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjKgOCv-nUjR",
        "outputId": "1e933359-d0f7-43da-c027-71c9f9604ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "noise_frames = np.load(\"/content/drive/My Drive/Colab Notebooks/signal_arr/noise_signal_8khz_1s.npy\")\n",
        "noise_stft_mag, noise_stft_ph = signal_to_spect(noise_frames)\n",
        "print(\"Noise STFT Mag and Phase shape: \", noise_stft_mag.shape, noise_stft_ph.shape)\n",
        "\n",
        "np.save(\"/content/drive/My Drive/Colab Notebooks/stft_mag_arr/noise_stft_mag\", noise_stft_mag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Noise STFT Mag and Phase shape:  (1815, 128, 128) (1815, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64xZLz36q3sB",
        "outputId": "13b0909b-7329-4c8f-91f9-96a6af79d329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clean_frames = np.load(\"/content/drive/My Drive/Colab Notebooks/signal_arr/clean_signal_8khz_1s.npy\")\n",
        "clean_stft_mag, clean_stft_ph = signal_to_spect(clean_frames)\n",
        "print(\"Clean STFT Mag and Phase shape: \", clean_stft_mag.shape, clean_stft_ph.shape)\n",
        "\n",
        "np.save(\"/content/drive/My Drive/Colab Notebooks/stft_mag_arr/clean_stft_mag\", clean_stft_mag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clean STFT Mag and Phase shape:  (1815, 128, 128) (1815, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9gE2dXmq8oF",
        "outputId": "136c1e1e-ed07-4d77-c34a-fd29be6b61f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "only_noise_frames = np.load(\"/content/drive/My Drive/Colab Notebooks/signal_arr/only_noise_signal_8khz_1s.npy\")\n",
        "only_noise_stft_mag, only_noise_stft_ph = signal_to_spect(only_noise_frames)\n",
        "print(\"Only Noise STFT Mag and Phase shape: \", only_noise_stft_mag.shape, only_noise_stft_ph.shape)\n",
        "\n",
        "np.save(\"/content/drive/My Drive/Colab Notebooks/stft_mag_arr/only_noise_stft_mag\", only_noise_stft_mag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Only Noise STFT Mag and Phase shape:  (1815, 128, 128) (1815, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDYUGGfFholP"
      },
      "source": [
        "### 4. Normalize the STFT components between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7US-GDg2hJ6"
      },
      "source": [
        "inp_x = np.load(\"/content/drive/My Drive/Colab Notebooks/stft_mag_arr/noise_stft_mag.npy\")\n",
        "out_x = np.load(\"/content/drive/My Drive/Colab Notebooks/stft_mag_arr/only_noise_stft_mag.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PlGcWwrTPDo",
        "outputId": "e18f58b4-b21a-427d-b9aa-e7c40edc254f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(stats.describe(inp_x.reshape(-1,1)))\n",
        "print(stats.describe(out_x.reshape(-1,1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DescribeResult(nobs=29736960, minmax=(array([-81.46199036]), array([31.83718109])), mean=array([-30.55498533]), variance=array([288.22655219]), skewness=array([0.11872211]), kurtosis=array([-0.49748866]))\n",
            "DescribeResult(nobs=29736960, minmax=(array([-100.]), array([31.83179092])), mean=array([-38.5884761]), variance=array([358.96261668]), skewness=array([-0.3461536]), kurtosis=array([-0.00910125]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihm6MPpCb9fD",
        "outputId": "5ebef959-cf63-4a4e-e338-da43993fd36b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1815, 128, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPquzx-S5Ur3"
      },
      "source": [
        "def scale_in(specto):\n",
        "    specto = (specto + 82)/114\n",
        "    return specto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXeBcEOR5dIO"
      },
      "source": [
        "def scale_out(specto):\n",
        "    specto = (specto + 100 )/132\n",
        "    return specto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6smrP3cr55Pl",
        "outputId": "556b7113-4eef-460e-a2f5-6256f66df461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "norm_inp_x = scale_in(inp_x)\n",
        "norm_out_x = scale_out(out_x)\n",
        "\n",
        "norm_inp_x = norm_inp_x[..., np.newaxis]\n",
        "norm_out_x = norm_out_x[..., np.newaxis]\n",
        "\n",
        "print(\"Shape of inp arr: \", norm_inp_x.shape)\n",
        "print(\"Shape of out arr: \", norm_out_x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of inp arr:  (1815, 128, 128, 1)\n",
            "Shape of out arr:  (1815, 128, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCMiIqTpR42t",
        "outputId": "e592bbc1-9388-48ef-b821-5343dd2f4f36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "\n",
        "print(stats.describe(norm_inp_x.reshape(-1,1)))\n",
        "print(stats.describe(norm_out_x.reshape(-1,1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DescribeResult(nobs=29736960, minmax=(array([0.00471938]), array([0.99857176])), mean=array([0.45127206]), variance=array([0.0221781]), skewness=array([0.11872211]), kurtosis=array([-0.49748866]))\n",
            "DescribeResult(nobs=29736960, minmax=(array([0.]), array([0.99872569])), mean=array([0.46523882]), variance=array([0.02060162]), skewness=array([-0.3461536]), kurtosis=array([-0.00910125]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZk6g4kMhols"
      },
      "source": [
        "### 5. Define the UNET model architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NXU_69h9fdX"
      },
      "source": [
        "def unet(pretrained_weights = None,input_size = (128,128,1)):\n",
        "    #size filter input\n",
        "    size_filter_in = 16\n",
        "    #normal initialization of weights\n",
        "    kernel_init = 'he_normal'\n",
        "    #To apply leaky relu after the conv layer \n",
        "    activation_layer = None\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(inputs)\n",
        "    conv1 = LeakyReLU()(conv1)\n",
        "    conv1 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv1)\n",
        "    conv1 = LeakyReLU()(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool1)\n",
        "    conv2 = LeakyReLU()(conv2)\n",
        "    conv2 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv2)\n",
        "    conv2 = LeakyReLU()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool2)\n",
        "    conv3 = LeakyReLU()(conv3)\n",
        "    conv3 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv3)\n",
        "    conv3 = LeakyReLU()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool3)\n",
        "    conv4 = LeakyReLU()(conv4)\n",
        "    conv4 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv4)\n",
        "    conv4 = LeakyReLU()(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(size_filter_in*16, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool4)\n",
        "    conv5 = LeakyReLU()(conv5)\n",
        "    conv5 = Conv2D(size_filter_in*16, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv5)\n",
        "    conv5 = LeakyReLU()(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(size_filter_in*8, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(drop5))\n",
        "    up6 = LeakyReLU()(up6)\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge6)\n",
        "    conv6 = LeakyReLU()(conv6)\n",
        "    conv6 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv6)\n",
        "    conv6 = LeakyReLU()(conv6)\n",
        "    up7 = Conv2D(size_filter_in*4, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(conv6))\n",
        "    up7 = LeakyReLU()(up7)\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge7)\n",
        "    conv7 = LeakyReLU()(conv7)\n",
        "    conv7 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv7)\n",
        "    conv7 = LeakyReLU()(conv7)\n",
        "    up8 = Conv2D(size_filter_in*2, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(conv7))\n",
        "    up8 = LeakyReLU()(up8)\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge8)\n",
        "    conv8 = LeakyReLU()(conv8)\n",
        "    conv8 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv8)\n",
        "    conv8 = LeakyReLU()(conv8)\n",
        "\n",
        "    up9 = Conv2D(size_filter_in, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(conv8))\n",
        "    up9 = LeakyReLU()(up9)\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge9)\n",
        "    conv9 = LeakyReLU()(conv9)\n",
        "    conv9 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv9)\n",
        "    conv9 = LeakyReLU()(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv9)\n",
        "    conv9 = LeakyReLU()(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'tanh')(conv9)\n",
        "\n",
        "    model = Model(inputs,conv10)\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = 'huber', metrics = ['mae'])\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzM_hYPzholw"
      },
      "source": [
        "### 6. Create the Train-Test split, initialise the model and checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUi159XF8Rn-",
        "outputId": "13be9caf-340f-4574-da4c-a9722dabb315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(norm_inp_x, norm_out_x, test_size=0.1)\n",
        "\n",
        "model = unet()\n",
        "chkpoint = ModelCheckpoint(\"/content/drive/My Drive/Colab Notebooks/model_chkpoint/best_model.h5\", verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_45\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_528 (Conv2D)             (None, 128, 128, 16) 160         input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_506 (LeakyReLU)     (None, 128, 128, 16) 0           conv2d_528[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_529 (Conv2D)             (None, 128, 128, 16) 2320        leaky_re_lu_506[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_507 (LeakyReLU)     (None, 128, 128, 16) 0           conv2d_529[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_88 (MaxPooling2D) (None, 64, 64, 16)   0           leaky_re_lu_507[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_530 (Conv2D)             (None, 64, 64, 32)   4640        max_pooling2d_88[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_508 (LeakyReLU)     (None, 64, 64, 32)   0           conv2d_530[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_531 (Conv2D)             (None, 64, 64, 32)   9248        leaky_re_lu_508[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_509 (LeakyReLU)     (None, 64, 64, 32)   0           conv2d_531[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_89 (MaxPooling2D) (None, 32, 32, 32)   0           leaky_re_lu_509[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_532 (Conv2D)             (None, 32, 32, 64)   18496       max_pooling2d_89[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_510 (LeakyReLU)     (None, 32, 32, 64)   0           conv2d_532[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_533 (Conv2D)             (None, 32, 32, 64)   36928       leaky_re_lu_510[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_511 (LeakyReLU)     (None, 32, 32, 64)   0           conv2d_533[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_90 (MaxPooling2D) (None, 16, 16, 64)   0           leaky_re_lu_511[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_534 (Conv2D)             (None, 16, 16, 128)  73856       max_pooling2d_90[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_512 (LeakyReLU)     (None, 16, 16, 128)  0           conv2d_534[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_535 (Conv2D)             (None, 16, 16, 128)  147584      leaky_re_lu_512[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_513 (LeakyReLU)     (None, 16, 16, 128)  0           conv2d_535[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 16, 16, 128)  0           leaky_re_lu_513[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_91 (MaxPooling2D) (None, 8, 8, 128)    0           dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_536 (Conv2D)             (None, 8, 8, 256)    295168      max_pooling2d_91[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_514 (LeakyReLU)     (None, 8, 8, 256)    0           conv2d_536[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_537 (Conv2D)             (None, 8, 8, 256)    590080      leaky_re_lu_514[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_515 (LeakyReLU)     (None, 8, 8, 256)    0           conv2d_537[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 8, 8, 256)    0           leaky_re_lu_515[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_88 (UpSampling2D) (None, 16, 16, 256)  0           dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_538 (Conv2D)             (None, 16, 16, 128)  131200      up_sampling2d_88[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_516 (LeakyReLU)     (None, 16, 16, 128)  0           conv2d_538[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_88 (Concatenate)    (None, 16, 16, 256)  0           dropout_44[0][0]                 \n",
            "                                                                 leaky_re_lu_516[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_539 (Conv2D)             (None, 16, 16, 128)  295040      concatenate_88[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_517 (LeakyReLU)     (None, 16, 16, 128)  0           conv2d_539[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_540 (Conv2D)             (None, 16, 16, 128)  147584      leaky_re_lu_517[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_518 (LeakyReLU)     (None, 16, 16, 128)  0           conv2d_540[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_89 (UpSampling2D) (None, 32, 32, 128)  0           leaky_re_lu_518[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_541 (Conv2D)             (None, 32, 32, 64)   32832       up_sampling2d_89[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_519 (LeakyReLU)     (None, 32, 32, 64)   0           conv2d_541[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_89 (Concatenate)    (None, 32, 32, 128)  0           leaky_re_lu_511[0][0]            \n",
            "                                                                 leaky_re_lu_519[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_542 (Conv2D)             (None, 32, 32, 64)   73792       concatenate_89[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_520 (LeakyReLU)     (None, 32, 32, 64)   0           conv2d_542[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_543 (Conv2D)             (None, 32, 32, 64)   36928       leaky_re_lu_520[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_521 (LeakyReLU)     (None, 32, 32, 64)   0           conv2d_543[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_90 (UpSampling2D) (None, 64, 64, 64)   0           leaky_re_lu_521[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_544 (Conv2D)             (None, 64, 64, 32)   8224        up_sampling2d_90[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_522 (LeakyReLU)     (None, 64, 64, 32)   0           conv2d_544[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_90 (Concatenate)    (None, 64, 64, 64)   0           leaky_re_lu_509[0][0]            \n",
            "                                                                 leaky_re_lu_522[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_545 (Conv2D)             (None, 64, 64, 32)   18464       concatenate_90[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_523 (LeakyReLU)     (None, 64, 64, 32)   0           conv2d_545[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_546 (Conv2D)             (None, 64, 64, 32)   9248        leaky_re_lu_523[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_524 (LeakyReLU)     (None, 64, 64, 32)   0           conv2d_546[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_91 (UpSampling2D) (None, 128, 128, 32) 0           leaky_re_lu_524[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_547 (Conv2D)             (None, 128, 128, 16) 2064        up_sampling2d_91[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_525 (LeakyReLU)     (None, 128, 128, 16) 0           conv2d_547[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_91 (Concatenate)    (None, 128, 128, 32) 0           leaky_re_lu_507[0][0]            \n",
            "                                                                 leaky_re_lu_525[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_548 (Conv2D)             (None, 128, 128, 16) 4624        concatenate_91[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_526 (LeakyReLU)     (None, 128, 128, 16) 0           conv2d_548[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_549 (Conv2D)             (None, 128, 128, 16) 2320        leaky_re_lu_526[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_527 (LeakyReLU)     (None, 128, 128, 16) 0           conv2d_549[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_550 (Conv2D)             (None, 128, 128, 2)  290         leaky_re_lu_527[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_528 (LeakyReLU)     (None, 128, 128, 2)  0           conv2d_550[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_551 (Conv2D)             (None, 128, 128, 1)  3           leaky_re_lu_528[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 1,941,093\n",
            "Trainable params: 1,941,093\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgQSAcJN-RuH"
      },
      "source": [
        "del norm_inp_x, norm_out_x, inp_x, out_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOzug_gMhol0"
      },
      "source": [
        "### 7. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqRlM5aG9TcL",
        "outputId": "6a28e789-1ff4-4ad0-88bf-5925135f801b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=20, batch_size=20, shuffle=True, callbacks=[chkpoint], verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0069 - mae: 0.0814\n",
            "Epoch 00001: val_loss did not improve from 0.00334\n",
            "82/82 [==============================] - 13s 163ms/step - loss: 0.0069 - mae: 0.0814 - val_loss: 0.0156 - val_mae: 0.1473\n",
            "Epoch 2/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0031 - mae: 0.0554\n",
            "Epoch 00002: val_loss did not improve from 0.00334\n",
            "82/82 [==============================] - 13s 157ms/step - loss: 0.0031 - mae: 0.0554 - val_loss: 0.0042 - val_mae: 0.0603\n",
            "Epoch 3/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0025 - mae: 0.0497\n",
            "Epoch 00003: val_loss did not improve from 0.00334\n",
            "82/82 [==============================] - 13s 156ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0042 - val_mae: 0.0598\n",
            "Epoch 4/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0025 - mae: 0.0495\n",
            "Epoch 00004: val_loss did not improve from 0.00334\n",
            "82/82 [==============================] - 13s 157ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0040 - val_mae: 0.0698\n",
            "Epoch 5/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0020 - mae: 0.0439\n",
            "Epoch 00005: val_loss did not improve from 0.00334\n",
            "82/82 [==============================] - 13s 156ms/step - loss: 0.0020 - mae: 0.0439 - val_loss: 0.0045 - val_mae: 0.0592\n",
            "Epoch 6/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0429\n",
            "Epoch 00006: val_loss did not improve from 0.00334\n",
            "82/82 [==============================] - 13s 156ms/step - loss: 0.0019 - mae: 0.0429 - val_loss: 0.0068 - val_mae: 0.0852\n",
            "Epoch 7/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0428\n",
            "Epoch 00007: val_loss did not improve from 0.00334\n",
            "82/82 [==============================] - 13s 156ms/step - loss: 0.0019 - mae: 0.0428 - val_loss: 0.0036 - val_mae: 0.0573\n",
            "Epoch 8/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0017 - mae: 0.0399\n",
            "Epoch 00008: val_loss improved from 0.00334 to 0.00304, saving model to /content/drive/My Drive/Colab Notebooks/model_chkpoint/best_model.h5\n",
            "82/82 [==============================] - 14s 169ms/step - loss: 0.0017 - mae: 0.0399 - val_loss: 0.0030 - val_mae: 0.0540\n",
            "Epoch 9/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0016 - mae: 0.0392\n",
            "Epoch 00009: val_loss did not improve from 0.00304\n",
            "82/82 [==============================] - 13s 156ms/step - loss: 0.0016 - mae: 0.0392 - val_loss: 0.0036 - val_mae: 0.0537\n",
            "Epoch 10/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0017 - mae: 0.0397\n",
            "Epoch 00010: val_loss improved from 0.00304 to 0.00272, saving model to /content/drive/My Drive/Colab Notebooks/model_chkpoint/best_model.h5\n",
            "82/82 [==============================] - 15s 182ms/step - loss: 0.0017 - mae: 0.0397 - val_loss: 0.0027 - val_mae: 0.0468\n",
            "Epoch 11/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0015 - mae: 0.0371\n",
            "Epoch 00011: val_loss improved from 0.00272 to 0.00230, saving model to /content/drive/My Drive/Colab Notebooks/model_chkpoint/best_model.h5\n",
            "82/82 [==============================] - 20s 242ms/step - loss: 0.0015 - mae: 0.0371 - val_loss: 0.0023 - val_mae: 0.0438\n",
            "Epoch 12/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0014 - mae: 0.0362\n",
            "Epoch 00012: val_loss did not improve from 0.00230\n",
            "82/82 [==============================] - 13s 157ms/step - loss: 0.0014 - mae: 0.0362 - val_loss: 0.0032 - val_mae: 0.0508\n",
            "Epoch 13/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0015 - mae: 0.0377\n",
            "Epoch 00013: val_loss did not improve from 0.00230\n",
            "82/82 [==============================] - 13s 156ms/step - loss: 0.0015 - mae: 0.0377 - val_loss: 0.0053 - val_mae: 0.0682\n",
            "Epoch 14/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0015 - mae: 0.0378\n",
            "Epoch 00014: val_loss did not improve from 0.00230\n",
            "82/82 [==============================] - 13s 156ms/step - loss: 0.0015 - mae: 0.0378 - val_loss: 0.0026 - val_mae: 0.0473\n",
            "Epoch 15/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0336\n",
            "Epoch 00015: val_loss did not improve from 0.00230\n",
            "82/82 [==============================] - 13s 156ms/step - loss: 0.0012 - mae: 0.0336 - val_loss: 0.0029 - val_mae: 0.0495\n",
            "Epoch 16/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0335\n",
            "Epoch 00016: val_loss did not improve from 0.00230\n",
            "82/82 [==============================] - 13s 156ms/step - loss: 0.0012 - mae: 0.0335 - val_loss: 0.0031 - val_mae: 0.0512\n",
            "Epoch 17/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0335\n",
            "Epoch 00017: val_loss improved from 0.00230 to 0.00194, saving model to /content/drive/My Drive/Colab Notebooks/model_chkpoint/best_model.h5\n",
            "82/82 [==============================] - 15s 181ms/step - loss: 0.0012 - mae: 0.0335 - val_loss: 0.0019 - val_mae: 0.0399\n",
            "Epoch 18/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0325\n",
            "Epoch 00018: val_loss did not improve from 0.00194\n",
            "82/82 [==============================] - 13s 156ms/step - loss: 0.0011 - mae: 0.0325 - val_loss: 0.0031 - val_mae: 0.0506\n",
            "Epoch 19/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0330\n",
            "Epoch 00019: val_loss did not improve from 0.00194\n",
            "82/82 [==============================] - 13s 156ms/step - loss: 0.0011 - mae: 0.0330 - val_loss: 0.0024 - val_mae: 0.0459\n",
            "Epoch 20/20\n",
            "82/82 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0312\n",
            "Epoch 00020: val_loss did not improve from 0.00194\n",
            "82/82 [==============================] - 13s 157ms/step - loss: 0.0011 - mae: 0.0312 - val_loss: 0.0030 - val_mae: 0.0523\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f80f9600b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpNggZAQhol3"
      },
      "source": [
        "##### Model metrics: loss: 0.0011 - mae: 0.0312 - val_loss: 0.0030 - val_mae: 0.0523 at Epoch 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qX1pA0xOxdw"
      },
      "source": [
        "model.save(\"saved_model/mag_best_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxpmBickhol5"
      },
      "source": [
        "### 8. Model Evaluation and Testing on samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B26DuhRQH9Lb"
      },
      "source": [
        "def inv_scaled_out(specto):\n",
        "    specto = specto * 132 - 100\n",
        "    return specto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkEW4WS4KJrf"
      },
      "source": [
        "def mag_ph_to_audio(mag, ph):\n",
        "    mag = librosa.core.db_to_amplitude(mag)\n",
        "    stft = mag*ph\n",
        "    istft = librosa.core.istft(stft)\n",
        "    return istft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTYj82IyJVDp"
      },
      "source": [
        "def specto_to_signal(specto, ph):\n",
        "    audio_signal = []\n",
        "    n_frames = specto.shape[0]\n",
        "    for i in range(n_frames):\n",
        "        audio_recons = mag_ph_to_audio(specto[i], ph[i])\n",
        "        audio_signal.append(audio_recons)\n",
        "    \n",
        "    return np.vstack(audio_signal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrRs93QrE5gK"
      },
      "source": [
        "loaded_model = tf.keras.models.load_model('saved_model/mag_best_model.h5')\n",
        "pred_audio_file = \"/content/drive/My Drive/Colab Notebooks/test voice.aac\"  \n",
        "\n",
        "signal, c_sig, o_n_sign = signal_creator(pred_audio_file, pred_audio_file)\n",
        "pred_frames = numpy_frame_creator(signal=signal, signal_length=len(signal)) \n",
        "print(\"Shape of raw signal: \")\n",
        "\n",
        "sp_mag, sp_ph = signal_to_spect(pred_frames) \n",
        "\n",
        "print(\"Spec mag shape: \", sp_mag.shape)\n",
        "print(\"Spec ph shape: \", sp_ph.shape)\n",
        "\n",
        "sp_mag_1 = scale_in(sp_mag) \n",
        "pred_x = sp_mag_1[..., np.newaxis]\n",
        "ph_pred_x = sp_ph[..., np.newaxis]\n",
        "\n",
        "print(\"Shape of input pred: \", pred_x.shape)\n",
        "\n",
        "\n",
        "pred_out = loaded_model.predict(pred_x)\n",
        "inv_scaled_pred_out = inv_scaled_out(pred_out) \n",
        "inv_scaled_pred_out = inv_scaled_pred_out.reshape(inv_scaled_pred_out.shape[0], inv_scaled_pred_out.shape[1], inv_scaled_pred_out.shape[2])\n",
        "\n",
        "\n",
        "noise_mask =  inv_scaled_pred_out   \n",
        "print(\"Shape of noise spec: \", noise_mask.shape)\n",
        "\n",
        "\n",
        "noise_mask_recons_numpy = specto_to_signal(noise_mask, sp_ph)\n",
        "print(\"Shape of noise signal: \", noise_mask_recons_numpy.shape)\n",
        "\n",
        "nb_samples = noise_mask_recons_numpy.shape[0]\n",
        "noise_mask_signal = (noise_mask_recons_numpy.reshape(-1,).T)\n",
        "print(\"Shape of noise mask: \", noise_mask_signal.shape)\n",
        "librosa.output.write_wav(\"test_voice_predicted_noise_mask.wav\", noise_mask_signal, SAMPLE_RATE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_mag = sp_mag     \n",
        "print(\"Shape of input spec: \", input_mag.shape)\n",
        "\n",
        "\n",
        "input_audio_numpy = specto_to_signal(input_mag, sp_ph)\n",
        "print(\"Shape of input signal: \", input_audio_numpy.shape)\n",
        "\n",
        "nb_samples = input_audio_numpy.shape[0]\n",
        "input_audio_signal = (input_audio_numpy.reshape(-1,).T)\n",
        "print(\"Shape of input signal: \", input_audio_signal.shape)\n",
        "librosa.output.write_wav(\"test_voice_original_clip.wav\", input_audio_signal, SAMPLE_RATE)\n",
        "\n",
        "\n",
        "\n",
        "librosa.output.write_wav(\"test_voice_denoised_input.wav\", input_audio_signal-noise_mask_signal, SAMPLE_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQk_ZMyKhomC"
      },
      "source": [
        "### 9. Graph plots of spectograms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDiVrDAg-c6y"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def make_plot_spectrogram(stftaudio_magnitude_db,sample_rate, hop_length_fft) :\n",
        "    \"\"\"This function plots a spectrogram\"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    librosa.display.specshow(stftaudio_magnitude_db, x_axis='time', y_axis='linear',\n",
        "                             sr=sample_rate, hop_length=hop_length_fft)\n",
        "    plt.colorbar()\n",
        "    title = 'hop_length={},  time_steps={},  fft_bins={}  (2D resulting shape: {})'\n",
        "    plt.title(title.format(hop_length_fft,\n",
        "                           stftaudio_magnitude_db.shape[1],\n",
        "                           stftaudio_magnitude_db.shape[0],\n",
        "                           stftaudio_magnitude_db.shape));\n",
        "    return\n",
        "\n",
        "def make_plot_phase(stft_phase,sample_rate,hop_length_fft) :\n",
        "    \"\"\"This function plots the phase in radian\"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    librosa.display.specshow(np.angle(stft_phase), x_axis='time', y_axis='linear',\n",
        "                             sr=sample_rate, hop_length=hop_length_fft)\n",
        "    plt.colorbar()\n",
        "    title = 'hop_length={},  time_steps={},  fft_bins={}  (2D resulting shape: {})'\n",
        "    plt.title(title.format(hop_length_fft,\n",
        "                           stft_phase.shape[1],\n",
        "                           stft_phase.shape[0],\n",
        "                           stft_phase.shape));\n",
        "    return\n",
        "\n",
        "def make_plot_time_serie(audio,sample_rate):\n",
        "    \"\"\"This function plots the audio as a time serie\"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    #plt.ylim(-0.05, 0.05)\n",
        "    plt.title('Audio')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.xlabel('Time(s)')\n",
        "    librosa.display.waveplot(audio, sr=sample_rate)\n",
        "    return\n",
        "\n",
        "\n",
        "def make_3plots_spec_voice_noise(stftvoicenoise_mag_db,stftnoise_mag_db,stftvoice_mag_db,sample_rate, hop_length_fft):\n",
        "    \"\"\"This function plots the spectrograms of noisy voice, noise and voice as a single plot \"\"\"\n",
        "    plt.figure(figsize=(8, 12))\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.title('Spectrogram voice + noise')\n",
        "    librosa.display.specshow(stftvoicenoise_mag_db, x_axis='time', y_axis='linear',sr=sample_rate, hop_length=hop_length_fft)\n",
        "    plt.colorbar()\n",
        "    plt.subplot(3, 1, 2)\n",
        "    plt.title('Spectrogram predicted voice')\n",
        "    librosa.display.specshow(stftnoise_mag_db, x_axis='time', y_axis='linear',sr=sample_rate, hop_length=hop_length_fft)\n",
        "    plt.colorbar()\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.title('Spectrogram true voice')\n",
        "    librosa.display.specshow(stftvoice_mag_db, x_axis='time', y_axis='linear',sr=sample_rate, hop_length=hop_length_fft)\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def make_3plots_phase_voice_noise(stftvoicenoise_phase,stftnoise_phase,stftvoice_phase,sample_rate, hop_length_fft):\n",
        "    \"\"\"This function plots the phase in radians of noisy voice, noise and voice as a single plot \"\"\"\n",
        "    plt.figure(figsize=(8, 12))\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.title('Phase (radian) voice + noise')\n",
        "    librosa.display.specshow(np.angle(stftvoicenoise_phase), x_axis='time', y_axis='linear',sr=sample_rate, hop_length=hop_length_fft)\n",
        "    plt.colorbar()\n",
        "    plt.subplot(3, 1, 2)\n",
        "    plt.title('Phase (radian) predicted voice')\n",
        "    librosa.display.specshow(np.angle(stftnoise_phase), x_axis='time', y_axis='linear',sr=sample_rate, hop_length=hop_length_fft)\n",
        "    plt.colorbar()\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.title('Phase (radian) true voice')\n",
        "    librosa.display.specshow(np.angle(stftvoice_phase), x_axis='time', y_axis='linear',sr=sample_rate, hop_length=hop_length_fft)\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def make_3plots_timeseries_voice_noise(clipvoicenoise,clipnoise,clipvoice, sample_rate) :\n",
        "    \"\"\"This function plots the time series of audio of noisy voice, noise and voice as a single plot \"\"\"\n",
        "    #y_ax_min = min(clipvoicenoise) - 0.15\n",
        "    #y_ax_max = max(clipvoicenoise) + 0.15\n",
        "\n",
        "    plt.figure(figsize=(18, 12))\n",
        "    plt.subplots_adjust(hspace=0.35)\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.title('Audio voice + noise')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.xlabel('Time(s)')\n",
        "    librosa.display.waveplot(clipvoicenoise, sr=sample_rate)\n",
        "    plt.ylim(-0.05, 0.05)\n",
        "    plt.subplot(3, 1, 2)\n",
        "    plt.title('Audio predicted voice')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.xlabel('Time(s)')\n",
        "    librosa.display.waveplot(clipnoise, sr=sample_rate)\n",
        "    plt.ylim(-0.05, 0.05)\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.title('Audio true voice')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.xlabel('Time(s)')\n",
        "    librosa.display.waveplot(clipvoice, sr=sample_rate)\n",
        "    plt.ylim(-0.05, 0.05)\n",
        "\n",
        "    return\n",
        "\n",
        "# for i in [8, 15, 20, 21, 26, 33]:\n",
        "file_number = \"33\" # \"my_voice\"\n",
        "\n",
        "input_file = \"eval_input_%s.wav\"%file_number\n",
        "output_file = \"eval_output_%s.wav\"%file_number\n",
        "actual_clean_file = \"clnsp%s.wav\"%file_number\n",
        "\n",
        "input_plot_name = input_file.split(\"_\")[-1].split(\".\")[0]\n",
        "output_plot_name = output_file.split(\"_\")[-1].split(\".\")[0]\n",
        "actual_clean_plot_name = actual_clean_file.split(\".\")[0][-2:]\n",
        "\n",
        "plt.figure(figsize=(8, 12))\n",
        "plt.subplots_adjust(hspace=0.35)\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.title(\"Noisy Voice Input Evaluation Sample (%s)\"%(file_number))\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "input_signal, input_sr = librosa.load(input_file, sr=SAMPLE_RATE)\n",
        "print(len(input_signal))\n",
        "input_stft = librosa.stft(input_signal, n_fft=N_FFT)\n",
        "input_magnitude, input_phase = librosa.magphase(input_stft)\n",
        "in_log_spec = librosa.amplitude_to_db(input_magnitude)\n",
        "librosa.display.specshow(in_log_spec, sr=SAMPLE_RATE, hop_length=HOP_LENGTH, cmap=\"inferno\")\n",
        "plt.colorbar()\n",
        "#plt.savefig(\"input_%s\"%(file_number))\n",
        "#plt.show()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.title(\"Denoised Voice Output Evaluation Sample (%s)\"%(file_number))\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "output_signal, output_sr = librosa.load(output_file, sr=SAMPLE_RATE)\n",
        "print(len(output_signal))\n",
        "output_stft = librosa.stft(output_signal, n_fft=N_FFT)\n",
        "output_magnitude, output_phase = librosa.magphase(output_stft)\n",
        "out_log_spec = librosa.amplitude_to_db(output_magnitude)\n",
        "librosa.display.specshow(out_log_spec, sr=SAMPLE_RATE, hop_length=HOP_LENGTH, cmap=\"inferno\")\n",
        "plt.colorbar()\n",
        "#plt.savefig(\"output_%s\"%(file_number))\n",
        "#plt.show()\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.title(\"Actual Clean voice of Evaluation Sample (%s)\"%(actual_clean_file))\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "actual_signal, actual_sr = librosa.load(actual_clean_file, sr=SAMPLE_RATE)\n",
        "print(len(actual_signal[:len(output_signal)]))\n",
        "actual_stft = librosa.stft(actual_signal[:len(output_signal)], n_fft=N_FFT)\n",
        "actual_magnitude, actual_phase = librosa.magphase(actual_stft)\n",
        "actual_log_spec = librosa.amplitude_to_db(actual_magnitude)\n",
        "librosa.display.specshow(actual_log_spec, sr=SAMPLE_RATE, hop_length=HOP_LENGTH, cmap=\"inferno\")\n",
        "plt.colorbar()\n",
        "plt.savefig(\"evaluation_sample_all_three_%s\"%(file_number))\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}